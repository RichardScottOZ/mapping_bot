{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From raw XYZ to clean selected data --- Selecting columns to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After areal survey, the geoscientist have to treat the data collected and save it to a organized database. So here, we'll learn how to use some functions of the GeoDataProcessing Python Libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The first thing that we have to do is to learn what are theese libraries and which of them we'll use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries\n",
    "##### numpy https://numpy.org/doc/stable/user/quickstart.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "\n",
    "import verde as vd\n",
    "import pooch\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grl/anaconda3/envs/graphite/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###      Selecting columns to work\n",
    "\n",
    "####    Here we'll use the gama and location data.\n",
    "    \n",
    "####    The location columns will be metadata and the gama will be the features.\n",
    "    \n",
    "####    This is much a manual process that depends on the type of organization that the mining company used to create the XYZ files. \n",
    "\n",
    "####    So we'll use a funtion called pandas.read_csv('  ') to:\n",
    "    \n",
    "######    1- load the xyz file delivered by the mining company to the RAM as a dataframe;\n",
    "######    2- and select the columns to work;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1039cols = 'UTME UTMN LON LAT MAGR THC UC KC CTC MAGB MAGC MAGD THB UB KB CTB FIDU TEMP ALTE ALTB'.split(' ')\n",
    "g1039 = pd.read_csv('../../../pml_grafita/xyz/spaulo_rjaneiro_sp.xyz',\n",
    "                   names = g1039cols,\n",
    "                   delim_whitespace = True,\n",
    "                   skiprows = 6,\n",
    "                   usecols = [\"UTME\",\"UTMN\",\"LON\",\"LAT\",\n",
    "                              \"THC\",\"UC\",\"KC\",\"CTC\",\n",
    "                              \"MAGR\"])\n",
    "'''\n",
    "g1105_cols = 'KB DATA BARO UB THB COSMICO CTB UUP ALTURA KPERC eU eTh CTEXP UTHRAZAO UTME UTMN UKRAZAO MDT THKRAZAO LIVE_TIME CTCOR KCOR THCOR UCOR HORA GPSALT LAT FIDUCIAL TEMP LONG'.split(' ')\n",
    "g1105 = pd.read_csv('../database/xyz/gama/1105_GamaLine.XYZ',\n",
    "                    names = g1105_cols,\n",
    "                    delim_whitespace = True,\n",
    "                    skiprows = 11,\n",
    "                    usecols = [\"UTME\",\"UTMN\",\"LAT\",\"LONG\",\n",
    "                               \"KPERC\",\"eU\",\"eTh\",\"CTCOR\",\n",
    "                               \"MDT\"])\n",
    "\n",
    "gArea14_cols = 'ALTURA BARO COSMICO CTB CTCOR CTEXP DATA eTh eU FIDUCIAL GPSALT HORA KB KCOR KPERC LATITUDE LIVE_TIME LONGITUDE MDT TEMP THB THCOR THKRAZAO UB UCOR UKRAZAO UTHRAZAO UUP X X_WGS Y Y_WGS'.split(' ')\n",
    "gArea14 = pd.read_csv('../database/xyz/gama/Area_14_gama.XYZ',\n",
    "                    names = gArea14_cols,\n",
    "                    delim_whitespace = True,\n",
    "                    skiprows = 8,\n",
    "                    usecols = [\"X\",\"Y\",\"LATITUDE\",\"LONGITUDE\",\"X_WGS\",\"Y_WGS\",\n",
    "                               \"KPERC\",\"eU\",\"eTh\",\"CTCOR\",\n",
    "                               \"MDT\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we use a funciton called dataframe.dropna() to delete the noData values from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1039.dropna(inplace=False)\n",
    "#g1105.dropna(inplace=False)\n",
    "#gArea14.dropna(inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can save the dataframe to a organized database as csv file.\n",
    "\n",
    "##### The function is pandas.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g1039.to_csv('../database/csv/gama/g1039_df.csv')\n",
    "#g1105.to_csv('../database/csv/gama/g1105_df.csv')\n",
    "#gArea14.to_csv('../database/csv/gama/gArea14_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1039 = pd.read_csv('../database/csv/OSR_g1039_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we can plot the values to visualize the area of the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(g1039.UTME, g1039.UTMN,\n",
    "            c= g1039.MAGR,\n",
    "            s=2)\n",
    "plt.colorbar()\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can use a function from Verde Library to select a region to observer a specific location.\n",
    "\n",
    "### I selected the area that cotains the Nappe Socorro geological mapping area made by (Freitas 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrr_treino = g1039[vd.inside((g1039.UTME,g1039.UTMN), region = [310000,347000,\n",
    "                                                               7465000,7510000])]\n",
    "\n",
    "scrr_test   = g1039[vd.inside((g1039.UTME,g1039.UTMN), region = [310000,347000,\n",
    "                                                               7420000,7465000])]\n",
    "\n",
    "#scrr_1105 = g1105[vd.inside((g1105.LONG,g1105.LAT), region = [-46.8, -45.9,\n",
    "#                                                             -23.1, -22.2])]\n",
    "\n",
    "    \n",
    "# Mapa de Socorro por Freitas.Mestrado\n",
    "# \n",
    "# -22.5829296112061009,-46.4997558593750000\n",
    "# -22.7087249755858984,-46.6257667541503977 \n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrr_treino.to_csv('../database/csv/scrr_treino.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrr_test.to_csv('../database/csv/scrr_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1105.CTCOR is different from 1039.CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames  = [scrr_1105,scrr_1039]\n",
    "scrr_df = pd.concat(frames) \n",
    "scrr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(scrr_test.UTME, scrr_test.UTMN,\n",
    "            c = scrr_test.MAGR,\n",
    "            s=1)\n",
    "plt.colorbar()\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(scrr_treino.UTME, scrr_treino.UTMN,\n",
    "            c=scrr_treino.MAGR,\n",
    "            s=1)\n",
    "plt.colorbar()\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a clean dataframe, only heading, values and a area selected, we can manipulate the data to generate better information.\n",
    "#### So we transform the location metadata to a unified geometry column called 'coordinates' or 'geometry'. And plotting this points to a cartesian or projected coordinated system we can visualize how well was the aerial survey was made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lat_ts (latitude of the true scalle ) = the mean value of the LAT of the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = pyproj.Proj(proj='utm', zone='23s', EPGS ='32723')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = (scrr_treino.UTME.values, scrr_treino.UTMN.values)\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(coordinates[0],coordinates[1],\n",
    "           c=scrr_treino.MAGR, s=1)\n",
    "plt.axis('scaled')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have to create a regular grid, decimating the data reducing the alliasing effect by a fuction called reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = vd.BlockReduce(np.median, spacing=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_coords, b_MAGR = reducer.filter(coordinates, scrr_treino.MAGR)\n",
    "\n",
    "#b_THC, b_UC, b_KC,b_CTC = reducer.filter(coordinates, scrr_1039.THC, scrr_1039.UC, scrr_1039.KC, scrr_1039.CTC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_MAGR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Here we visualize the residual points after the blocked reductionm and observe that the sampled points are not perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(b_coords[0],b_coords[1],\n",
    "            c    = b_MAGR,\n",
    "            cmap = 'magma',\n",
    "            s    = 2)\n",
    "plt.axis('scaled')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_MAGR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrr_treino.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridding with splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spline = vd.Spline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spline.fit(b_coords, b_MAGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Predicting the real non decimated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = spline.predict(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(coordinates[0],coordinates[1],\n",
    "            c=predicted,\n",
    "            cmap='magma',\n",
    "            s=1)\n",
    "plt.axis('scaled')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the difference between the raw data and the predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = scrr_treino.MAGR - predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = vd.maxabs(residuals)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(coordinates[0],coordinates[1],\n",
    "            c=residuals,\n",
    "            cmap='RdBu_r',\n",
    "            s=2,\n",
    "            vmin=-scale,vmax=scale)\n",
    "plt.axis('scaled')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Now generating a pixel data from point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = vd.get_region(coordinates)\n",
    "grid_coords = vd.grid_coordinates(region, spacing = 200)\n",
    "\n",
    "# This griding resolution is 10x the real data resolution (1000m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_MAGR = spline.predict(grid_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(grid_coords[0], grid_coords[1],\n",
    "            c=grid_MAGR,\n",
    "            cmap='magma',\n",
    "            s=2)\n",
    "plt.axis('scaled')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = spline.grid(spacing=200, data_names=['MAGR'])\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.MAGR.plot(figsize=(8,8),\n",
    "               cmap='magma')\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating pixels that is too fars from a real surveyed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = vd.distance_mask(coordinates, maxdist=1000, grid=grid)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.MAGR.plot(figsize=(8,8),cmap='Greys')\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Chanining operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  First we create the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_MAGR = vd.Chain([\n",
    "    ('trend',  vd.Trend(degree=2)),\n",
    "    ('reduce', vd.BlockReduce(np.median, spacing=200)),\n",
    "    ('spline', vd.Spline()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_MAGR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we fit within the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_MAGR.fit(coordinates, scrr_treino.MAGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGR_grid = chain_MAGR.grid(spacing=200, data_names=['MAGR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGR_grid = vd.distance_mask(coordinates, maxdist=1000, grid=MAGR_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGR_grid.MAGR.plot(figsize=(8,8), cmap='magma')\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = vd.train_test_split(coordinates, scrr_treino.MAGR,\n",
    "                                 test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we can visualize the train information:\n",
    "    1- two arrays representing coordinates;\n",
    "    2- a touple of one array of data training set\n",
    "    3- a column representing the wheights of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(train[0][0], train[0][1], '.b', markersize=2)\n",
    "plt.plot(test[0][0], test[0][1], '.r', markersize=2)\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_MAGR.fit(*train)\n",
    "# *train   ---> chain.fit(train[0], train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_MAGR.score(*test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = vd.train_test_split(coordinates, scrr_treino.MAGR, test_size=0.1, spacing=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(train[0][0], train[0][1], '.b', markersize=2)\n",
    "plt.plot(test[0][0], test[0][1], '.r', markersize=2)\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_MAGR.fit(*train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_MAGR.score(*test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv     = vd.BlockKFold(spacing=200,\n",
    "                  n_splits=10,\n",
    "                  shuffle=True)\n",
    "scores = vd.cross_val_score(chain_MAGR,\n",
    "                            coordinates,\n",
    "                            scrr_treino.MAGR,\n",
    "                            cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(scores, bins ='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now reproducing this fit process for each feature.\n",
    "It is possible to create a chainned operation with a higher degree trend to interpolate more then 2 dimentions \"coordinates x Feature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_CTC = vd.Chain([\n",
    "    ('trend',  vd.Trend(degree=2)),\n",
    "    ('reduce', vd.BlockReduce(np.median, spacing=200)),\n",
    "    ('spline', vd.Spline()),\n",
    "])\n",
    "\n",
    "chain_CTC.fit(coordinates, scrr_treino.CTC)\n",
    "\n",
    "CTC_grid = chain_CTC.grid(spacing=200, data_names=['CTC'])\n",
    "CTC_grid = vd.distance_mask(coordinates, maxdist=1000, grid=CTC_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTC_grid.CTC.plot(figsize=(8,8), cmap='viridis')\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_KC = vd.Chain([\n",
    "    ('trend',  vd.Trend(degree=2)),\n",
    "    ('reduce', vd.BlockReduce(np.median, spacing=200)),\n",
    "    ('spline', vd.Spline()),\n",
    "])\n",
    "\n",
    "chain_KC.fit(coordinates, scrr_treino.KC)\n",
    "\n",
    "KC_grid = chain_KC.grid(spacing=200, data_names=['KC'])\n",
    "KC_grid = vd.distance_mask(coordinates, maxdist=1000, grid=KC_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_THC = vd.Chain([\n",
    "    ('trend',  vd.Trend(degree=2)),\n",
    "    ('reduce', vd.BlockReduce(np.median, spacing=200)),\n",
    "    ('spline', vd.Spline()),\n",
    "])\n",
    "\n",
    "chain_THC.fit(coordinates, scrr_treino.THC)\n",
    "\n",
    "THC_grid = chain_THC.grid(spacing=200, data_names=['THC'])\n",
    "THC_grid = vd.distance_mask(coordinates, maxdist=1000, grid=THC_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_UC = vd.Chain([\n",
    "    ('trend',  vd.Trend(degree=2)),\n",
    "    ('reduce', vd.BlockReduce(np.median, spacing=200)),\n",
    "    ('spline', vd.Spline()),\n",
    "])\n",
    "\n",
    "chain_UC.fit(coordinates, scrr_treino.UC)\n",
    "\n",
    "UC_grid = chain_UC.grid(spacing=200, data_names=['UC'])\n",
    "UC_grid = vd.distance_mask(coordinates, maxdist=1000, grid=UC_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Ploting the grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTC_grid.CTC.plot(figsize=(6,6), cmap='viridis')\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KC_scale = vd.maxabs(KC_grid.KC)\n",
    "\n",
    "KC_grid.KC.plot(figsize=(6,6), cmap='viridis')\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THC_grid.THC.plot(figsize=(6,6), cmap='viridis')\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative values were present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UC_grid.UC.plot(figsize=(8,8), cmap='viridis')\n",
    "plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the grid to a organized database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGR_grid.to_netcdf('../database/grid/Socorro/b1000/Socorro_MAGR.nc')\n",
    "CTC_grid.to_netcdf('../database/grid/Socorro/b1000/Socorro_CTC.nc')\n",
    "UC_grid.to_netcdf('../database/grid/Socorro/b1000/Socorro_UC.nc')\n",
    "THC_grid.to_netcdf('../database/grid/Socorro/b1000/Socorro_THC.nc')\n",
    "KC_grid.to_netcdf('../database/grid/Socorro/b1000/Socorro_KC.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litologia = pd.read_csv('../database/csv/litologia/FScrr_litologia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litologia = gpd.read_file('../database/csv/litologia/FScrr_lito_shp.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTC_grid.CTC.plot(figsize=(6,6), cmap='viridis')\n",
    "litologia.geometry.plot()\n",
    "plt.axis('scaled')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
